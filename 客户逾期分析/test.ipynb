{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 目录\n",
    "[1 数据探索](#1)\n",
    "\n",
    "[1.1 删除和预测无关的数据](#1.1)\n",
    "\n",
    "[1.2  查看行列缺失比例](#1.2)\n",
    "\n",
    "[1.3 处理类别特征](#1.3)\n",
    "\n",
    "[1.4 特征标准差探索](#1.4)\n",
    "\n",
    "[1.5 缺失值填充和特征编码](#1.5)\n",
    "\n",
    "[1.6 构造特征矩阵](#1.6)\n",
    "\n",
    "[1.7 划分训练集和测试集](#1.7)\n",
    "\n",
    "[2 模型选择](#2)\n",
    "\n",
    "[2.1 LR](#2.1)\n",
    "\n",
    "[2.2 SVM](#2.2)\n",
    "\n",
    "[2.3 DT](#2.3)\n",
    "\n",
    "[2.4 XGBoost](#2.4)\n",
    "\n",
    "[2.5 LightGBM](#2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='1'></a>\n",
    "# 1 数据探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 90)\n"
     ]
    }
   ],
   "source": [
    "#encoding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/data.csv', encoding='GB18030')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                u'Unnamed: 0',\n",
       "                                           u'custid',\n",
       "                                         u'trade_no',\n",
       "                                     u'bank_card_no',\n",
       "                               u'low_volume_percent',\n",
       "                            u'middle_volume_percent',\n",
       "            u'take_amount_in_later_12_month_highest',\n",
       "                u'trans_amount_increase_rate_lately',\n",
       "                             u'trans_activity_month',\n",
       "                               u'trans_activity_day',\n",
       "                                       u'transd_mcc',\n",
       "                       u'trans_days_interval_filter',\n",
       "                              u'trans_days_interval',\n",
       "                                u'regional_mobility',\n",
       "                                  u'student_feature',\n",
       "                             u'repayment_capability',\n",
       "                                     u'is_high_user',\n",
       "                        u'number_of_trans_from_2011',\n",
       "                           u'first_transaction_time',\n",
       "                          u'historical_trans_amount',\n",
       "                             u'historical_trans_day',\n",
       "                                u'rank_trad_1_month',\n",
       "                             u'trans_amount_3_month',\n",
       "                  u'avg_consume_less_12_valid_month',\n",
       "                                              u'abs',\n",
       "                     u'top_trans_count_last_1_month',\n",
       "                          u'avg_price_last_12_month',\n",
       "                u'avg_price_top_last_12_valid_month',\n",
       "                          u'reg_preference_for_trad',\n",
       "                      u'trans_top_time_last_1_month',\n",
       "                      u'trans_top_time_last_6_month',\n",
       "                    u'consume_top_time_last_1_month',\n",
       "                    u'consume_top_time_last_6_month',\n",
       "                 u'cross_consume_count_last_1_month',\n",
       "           u'trans_fail_top_count_enum_last_1_month',\n",
       "           u'trans_fail_top_count_enum_last_6_month',\n",
       "          u'trans_fail_top_count_enum_last_12_month',\n",
       "                   u'consume_mini_time_last_1_month',\n",
       "             u'max_cumulative_consume_later_1_month',\n",
       "                  u'max_consume_count_later_6_month',\n",
       "              u'railway_consume_count_last_12_month',\n",
       "       u'pawns_auctions_trusts_consume_last_1_month',\n",
       "       u'pawns_auctions_trusts_consume_last_6_month',\n",
       "               u'jewelry_consume_count_last_6_month',\n",
       "                                           u'status',\n",
       "                                           u'source',\n",
       "                            u'first_transaction_day',\n",
       "                          u'trans_day_last_12_month',\n",
       "                                          u'id_name',\n",
       "                                      u'apply_score',\n",
       "                                u'apply_credibility',\n",
       "                                  u'query_org_count',\n",
       "                              u'query_finance_count',\n",
       "                                 u'query_cash_count',\n",
       "                                  u'query_sum_count',\n",
       "                                u'latest_query_time',\n",
       "                           u'latest_one_month_apply',\n",
       "                         u'latest_three_month_apply',\n",
       "                           u'latest_six_month_apply',\n",
       "                                      u'loans_score',\n",
       "                       u'loans_credibility_behavior',\n",
       "                                      u'loans_count',\n",
       "                               u'loans_settle_count',\n",
       "                              u'loans_overdue_count',\n",
       "                         u'loans_org_count_behavior',\n",
       "                       u'consfin_org_count_behavior',\n",
       "                                 u'loans_cash_count',\n",
       "                            u'latest_one_month_loan',\n",
       "                          u'latest_three_month_loan',\n",
       "                            u'latest_six_month_loan',\n",
       "                                  u'history_suc_fee',\n",
       "                                 u'history_fail_fee',\n",
       "                             u'latest_one_month_suc',\n",
       "                            u'latest_one_month_fail',\n",
       "                                  u'loans_long_time',\n",
       "                                u'loans_latest_time',\n",
       "                               u'loans_credit_limit',\n",
       "                          u'loans_credibility_limit',\n",
       "                          u'loans_org_count_current',\n",
       "                              u'loans_product_count',\n",
       "                                  u'loans_max_limit',\n",
       "                                  u'loans_avg_limit',\n",
       "                             u'consfin_credit_limit',\n",
       "                              u'consfin_credibility',\n",
       "                        u'consfin_org_count_current',\n",
       "                            u'consfin_product_count',\n",
       "                                u'consfin_max_limit',\n",
       "                                u'consfin_avg_limit',\n",
       "                                 u'latest_query_day',\n",
       "                                 u'loans_latest_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.1'></a>\n",
    "## 1.1 删除和预测无关的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'source'和'bank_card_no'值无区分度\n",
    "# ‘custid’、‘trade_no’、‘id_name’和预测无关\n",
    "data = data.drop(['custid', 'trade_no', 'bank_card_no', 'id_name', 'source'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Unnamed: 0'和预测无关\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先删除data\n",
    "data = data.drop(['first_transaction_time', 'latest_query_time', 'loans_latest_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "## 1.2 查看行列缺失比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04% low_volume_percent\n",
      "0.04% middle_volume_percent\n",
      "0.00% take_amount_in_later_12_month_highest\n",
      "0.06% trans_amount_increase_rate_lately\n",
      "0.04% trans_activity_month\n",
      "0.04% trans_activity_day\n",
      "0.04% transd_mcc\n",
      "0.17% trans_days_interval_filter\n",
      "0.04% trans_days_interval\n",
      "0.04% regional_mobility\n",
      "63.06% student_feature\n",
      "0.00% repayment_capability\n",
      "0.00% is_high_user\n",
      "0.04% number_of_trans_from_2011\n",
      "0.00% historical_trans_amount\n",
      "0.04% historical_trans_day\n",
      "0.04% rank_trad_1_month\n",
      "0.00% trans_amount_3_month\n",
      "0.04% avg_consume_less_12_valid_month\n",
      "0.00% abs\n",
      "0.04% top_trans_count_last_1_month\n",
      "0.00% avg_price_last_12_month\n",
      "2.19% avg_price_top_last_12_valid_month\n",
      "0.04% reg_preference_for_trad\n",
      "0.17% trans_top_time_last_1_month\n",
      "0.17% trans_top_time_last_6_month\n",
      "0.17% consume_top_time_last_1_month\n",
      "0.17% consume_top_time_last_6_month\n",
      "8.96% cross_consume_count_last_1_month\n",
      "0.34% trans_fail_top_count_enum_last_1_month\n",
      "0.34% trans_fail_top_count_enum_last_6_month\n",
      "0.34% trans_fail_top_count_enum_last_12_month\n",
      "0.55% consume_mini_time_last_1_month\n",
      "0.00% max_cumulative_consume_later_1_month\n",
      "0.17% max_consume_count_later_6_month\n",
      "0.25% railway_consume_count_last_12_month\n",
      "0.00% pawns_auctions_trusts_consume_last_1_month\n",
      "0.00% pawns_auctions_trusts_consume_last_6_month\n",
      "0.25% jewelry_consume_count_last_6_month\n",
      "0.00% status\n",
      "0.04% first_transaction_day\n",
      "0.04% trans_day_last_12_month\n",
      "6.39% apply_score\n",
      "6.39% apply_credibility\n",
      "6.39% query_org_count\n",
      "6.39% query_finance_count\n",
      "6.39% query_cash_count\n",
      "6.39% query_sum_count\n",
      "6.39% latest_one_month_apply\n",
      "6.39% latest_three_month_apply\n",
      "6.39% latest_six_month_apply\n",
      "6.25% loans_score\n",
      "6.25% loans_credibility_behavior\n",
      "6.25% loans_count\n",
      "6.25% loans_settle_count\n",
      "6.25% loans_overdue_count\n",
      "6.25% loans_org_count_behavior\n",
      "6.25% consfin_org_count_behavior\n",
      "6.25% loans_cash_count\n",
      "6.25% latest_one_month_loan\n",
      "6.25% latest_three_month_loan\n",
      "6.25% latest_six_month_loan\n",
      "6.25% history_suc_fee\n",
      "6.25% history_fail_fee\n",
      "6.25% latest_one_month_suc\n",
      "6.25% latest_one_month_fail\n",
      "6.25% loans_long_time\n",
      "6.25% loans_credit_limit\n",
      "6.25% loans_credibility_limit\n",
      "6.25% loans_org_count_current\n",
      "6.25% loans_product_count\n",
      "6.25% loans_max_limit\n",
      "6.25% loans_avg_limit\n",
      "6.25% consfin_credit_limit\n",
      "6.25% consfin_credibility\n",
      "6.25% consfin_org_count_current\n",
      "6.25% consfin_product_count\n",
      "6.25% consfin_max_limit\n",
      "6.25% consfin_avg_limit\n",
      "6.39% latest_query_day\n",
      "6.25% loans_latest_day\n"
     ]
    }
   ],
   "source": [
    "# 统计各个列缺失值所占比例\n",
    "for i in data.columns:\n",
    "    d = len(data) - data[i].count()\n",
    "    r = (float(d) / len(data)) * 100\n",
    "    # rate = '%.2f%%' % r\n",
    "    # print 'name: ', str(i).ljust(10),'d: ', str(d).ljust(4), 'rate: ', rate\n",
    "    print '%.2f%%' % r, i\n",
    "\n",
    "# 由下图统计可以看出，‘student_feature’列缺失一半以上，且本列为类别类型，可以将缺失值用-1填充，相当于“是否缺失”当成另一种类别。\n",
    "# 其他列缺失概率比较小，可以用中值填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 81)\n",
      "(4754, 82)\n"
     ]
    }
   ],
   "source": [
    "# 缺失个数作为一种特征，衡量用户的信息完善程度\n",
    "miss_rate = []\n",
    "for i in range(len(data)):\n",
    "    temp = float((data[i:i+1]).count().sum()) / len(data.columns)\n",
    "    miss_rate.append(temp)\n",
    "\n",
    "print data.shape\n",
    "data['miss_rate'] = miss_rate\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.987654\n",
      "1       1.000000\n",
      "2       0.987654\n",
      "3       0.987654\n",
      "4       0.987654\n",
      "5       1.000000\n",
      "6       0.962963\n",
      "7       0.506173\n",
      "8       0.987654\n",
      "9       1.000000\n",
      "10      0.987654\n",
      "11      1.000000\n",
      "12      1.000000\n",
      "13      0.975309\n",
      "14      0.987654\n",
      "15      0.987654\n",
      "16      0.987654\n",
      "17      1.000000\n",
      "18      1.000000\n",
      "19      0.987654\n",
      "20      1.000000\n",
      "21      0.987654\n",
      "22      0.987654\n",
      "23      0.987654\n",
      "24      1.000000\n",
      "25      0.975309\n",
      "26      1.000000\n",
      "27      1.000000\n",
      "28      1.000000\n",
      "29      0.876543\n",
      "          ...   \n",
      "4724    1.000000\n",
      "4725    0.975309\n",
      "4726    0.987654\n",
      "4727    0.987654\n",
      "4728    0.987654\n",
      "4729    0.975309\n",
      "4730    1.000000\n",
      "4731    1.000000\n",
      "4732    0.975309\n",
      "4733    0.987654\n",
      "4734    0.987654\n",
      "4735    1.000000\n",
      "4736    1.000000\n",
      "4737    1.000000\n",
      "4738    0.987654\n",
      "4739    0.987654\n",
      "4740    0.987654\n",
      "4741    1.000000\n",
      "4742    1.000000\n",
      "4743    0.987654\n",
      "4744    0.987654\n",
      "4745    0.987654\n",
      "4746    0.518519\n",
      "4747    0.987654\n",
      "4748    0.975309\n",
      "4749    1.000000\n",
      "4750    1.000000\n",
      "4751    0.987654\n",
      "4752    0.987654\n",
      "4753    1.000000\n",
      "Name: miss_rate, Length: 4754, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print data['miss_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.3'></a>\n",
    "## 1.3 处理类别特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1950\n",
       "2.0    1515\n",
       "4.0     802\n",
       "1.0     446\n",
       "5.0      39\n",
       "Name: regional_mobility, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'regional_mobility'列的统计，按类别特征处理\n",
    "data['regional_mobility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "一线城市    3403\n",
       "三线城市    1064\n",
       "境外       150\n",
       "二线城市     131\n",
       "其他城市       4\n",
       "Name: reg_preference_for_trad, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'reg_preference_for_trad'列的统计，按类别特征处理\n",
    "data['reg_preference_for_trad'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1754\n",
       "2.0       2\n",
       "Name: student_feature, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'student_feature'列的统计，按类别特征处理\n",
    "data['student_feature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4701\n",
       "1      53\n",
       "Name: is_high_user, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'is_high_user'列的统计，按类别特征处理\n",
    "data['is_high_user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3561\n",
       "1    1193\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'status'列的统计，预测变量，正负样本接近1：3，可以不做处理。\n",
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 76)\n",
      "(4754, 82)\n"
     ]
    }
   ],
   "source": [
    "# 将刚刚被归类为类别变量和预测变量的列去掉，生成data_temp，数值特征为77维，类别特征为5维\n",
    "data_temp = data\n",
    "data_temp = data_temp.drop(['regional_mobility', 'reg_preference_for_trad', 'student_feature', 'is_high_user', 'status', 'miss_rate'], axis = 1)\n",
    "print data_temp.shape\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.4'></a>\n",
    "## 1.4 特征标准差探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "0.04 low_volume_percent\n",
      "0.14 middle_volume_percent\n",
      "3923.97 take_amount_in_later_12_month_highest\n",
      "694.18 trans_amount_increase_rate_lately\n",
      "0.20 trans_activity_month\n",
      "0.17 trans_activity_day\n",
      "4.48 transd_mcc\n",
      "22.72 trans_days_interval_filter\n",
      "16.47 trans_days_interval\n",
      "52217.83 repayment_capability\n",
      "10.06 number_of_trans_from_2011\n",
      "320493.12 historical_trans_amount\n",
      "99.69 historical_trans_day\n",
      "0.26 rank_trad_1_month\n",
      "101746.13 trans_amount_3_month\n",
      "1.39 avg_consume_less_12_valid_month\n",
      "27007.60 abs\n",
      "0.35 top_trans_count_last_1_month\n",
      "765.87 avg_price_last_12_month\n",
      "0.10 avg_price_top_last_12_valid_month\n",
      "5.32 trans_top_time_last_1_month\n",
      "12.96 trans_top_time_last_6_month\n",
      "5.46 consume_top_time_last_1_month\n",
      "13.13 consume_top_time_last_6_month\n",
      "2.34 cross_consume_count_last_1_month\n",
      "1.91 trans_fail_top_count_enum_last_1_month\n",
      "4.46 trans_fail_top_count_enum_last_6_month\n",
      "4.76 trans_fail_top_count_enum_last_12_month\n",
      "374267.23 consume_mini_time_last_1_month\n",
      "10813.45 max_cumulative_consume_later_1_month\n",
      "5.68 max_consume_count_later_6_month\n",
      "0.48 railway_consume_count_last_12_month\n",
      "6616.69 pawns_auctions_trusts_consume_last_1_month\n",
      "28191.13 pawns_auctions_trusts_consume_last_6_month\n",
      "0.20 jewelry_consume_count_last_6_month\n",
      "537.11 first_transaction_day\n",
      "19.07 trans_day_last_12_month\n",
      "51.17 apply_score\n",
      "4.17 apply_credibility\n",
      "7.04 query_org_count\n",
      "3.81 query_finance_count\n",
      "2.60 query_cash_count\n",
      "11.30 query_sum_count\n",
      "4.53 latest_one_month_apply\n",
      "7.62 latest_three_month_apply\n",
      "9.27 latest_six_month_apply\n",
      "60.95 loans_score\n",
      "2.23 loans_credibility_behavior\n",
      "24.61 loans_count\n",
      "21.69 loans_settle_count\n",
      "3.15 loans_overdue_count\n",
      "7.45 loans_org_count_behavior\n",
      "2.97 consfin_org_count_behavior\n",
      "5.37 loans_cash_count\n",
      "1.50 latest_one_month_loan\n",
      "3.46 latest_three_month_loan\n",
      "10.83 latest_six_month_loan\n",
      "30.35 history_suc_fee\n",
      "25.09 history_fail_fee\n",
      "1.94 latest_one_month_suc\n",
      "3.89 latest_one_month_fail\n",
      "35.77 loans_long_time\n",
      "708.95 loans_credit_limit\n",
      "10.85 loans_credibility_limit\n",
      "5.37 loans_org_count_current\n",
      "5.76 loans_product_count\n",
      "1474.21 loans_max_limit\n",
      "583.42 loans_avg_limit\n",
      "7371.26 consfin_credit_limit\n",
      "14.54 consfin_credibility\n",
      "2.97 consfin_org_count_current\n",
      "3.41 consfin_product_count\n",
      "14301.04 consfin_max_limit\n",
      "5679.42 consfin_avg_limit\n",
      "37.73 latest_query_day\n",
      "53.49 loans_latest_day\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# 统计各个列标准差，将标准差小于0.1的特征剔除，数值特征变为71维\n",
    "print (len(data_temp.columns))\n",
    "for i in data_temp.columns:\n",
    "    r = data_temp[i].std()\n",
    "    print '%.2f' % r, i\n",
    "    \n",
    "    if r < 0.1:\n",
    "        data_temp = data_temp.drop([i], axis = 1)\n",
    "print (len(data_temp.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='1.5'></a>\n",
    "## 1.5 缺失值填充和特征编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_volume_percent\n",
      "trans_amount_increase_rate_lately\n",
      "trans_activity_month\n",
      "trans_activity_day\n",
      "transd_mcc\n",
      "trans_days_interval_filter\n",
      "trans_days_interval\n",
      "number_of_trans_from_2011\n",
      "historical_trans_day\n",
      "rank_trad_1_month\n",
      "avg_consume_less_12_valid_month\n",
      "top_trans_count_last_1_month\n",
      "avg_price_top_last_12_valid_month\n",
      "trans_top_time_last_1_month\n",
      "trans_top_time_last_6_month\n",
      "consume_top_time_last_1_month\n",
      "consume_top_time_last_6_month\n",
      "cross_consume_count_last_1_month\n",
      "trans_fail_top_count_enum_last_1_month\n",
      "trans_fail_top_count_enum_last_6_month\n",
      "trans_fail_top_count_enum_last_12_month\n",
      "consume_mini_time_last_1_month\n",
      "max_consume_count_later_6_month\n",
      "railway_consume_count_last_12_month\n",
      "jewelry_consume_count_last_6_month\n",
      "first_transaction_day\n",
      "trans_day_last_12_month\n",
      "apply_score\n",
      "apply_credibility\n",
      "query_org_count\n",
      "query_finance_count\n",
      "query_cash_count\n",
      "query_sum_count\n",
      "latest_one_month_apply\n",
      "latest_three_month_apply\n",
      "latest_six_month_apply\n",
      "loans_score\n",
      "loans_credibility_behavior\n",
      "loans_count\n",
      "loans_settle_count\n",
      "loans_overdue_count\n",
      "loans_org_count_behavior\n",
      "consfin_org_count_behavior\n",
      "loans_cash_count\n",
      "latest_one_month_loan\n",
      "latest_three_month_loan\n",
      "latest_six_month_loan\n",
      "history_suc_fee\n",
      "history_fail_fee\n",
      "latest_one_month_suc\n",
      "latest_one_month_fail\n",
      "loans_long_time\n",
      "loans_credit_limit\n",
      "loans_credibility_limit\n",
      "loans_org_count_current\n",
      "loans_product_count\n",
      "loans_max_limit\n",
      "loans_avg_limit\n",
      "consfin_credit_limit\n",
      "consfin_credibility\n",
      "consfin_org_count_current\n",
      "consfin_product_count\n",
      "consfin_max_limit\n",
      "consfin_avg_limit\n",
      "latest_query_day\n",
      "loans_latest_day\n"
     ]
    }
   ],
   "source": [
    "# 接下来对类别特征和数值特征进行填充\n",
    "# 数值特征和类别特征均用用中值进行填充\n",
    "# 缺失值特征特别大的特征‘student_feature’用‘-1’填充\n",
    "for i in data_temp.columns:\n",
    "    temp = data_temp[i].isnull().sum()\n",
    "    if temp:\n",
    "        print i\n",
    "        data_temp[i].fillna(data_temp[i].median(), inplace = True)\n",
    "\n",
    "# 数值特征归一化 \n",
    "# 从sklearn.preprocessing导入StandardScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "# 标准化数据，保证每个维度的特征数据方差为1，均值为0，使得预测结果不会被某些维度过大的特征值而主导  \n",
    "ss = StandardScaler()  \n",
    "# fit_transform()先拟合数据，再标准化  \n",
    "data_temp = ss.fit_transform(data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98765432  1.          0.98765432 ...,  0.98765432  0.98765432  1.        ]\n",
      "(4754,)\n",
      "(4754, 1)\n"
     ]
    }
   ],
   "source": [
    "a5 = data['miss_rate']\n",
    "b5 = a5.as_matrix()\n",
    "print b5\n",
    "print b5.shape\n",
    "b5 = b5.reshape(len(b5), 1)\n",
    "print b5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n",
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]]\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "(4754, 3) (4754, 5) (4754, 5) (4754, 2)\n"
     ]
    }
   ],
   "source": [
    "# 类别特征one-hot编码\n",
    "\n",
    "a1 = data['student_feature']\n",
    "#print a\n",
    "a1.fillna(-1, inplace = True)\n",
    "# print a\n",
    "b1 = a1.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder1 = LabelEncoder()\n",
    "integer_encoded1 = label_encoder1.fit_transform(b1)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder1 = OneHotEncoder(sparse=False)\n",
    "integer_encoded1 = integer_encoded1.reshape(len(integer_encoded1), 1)\n",
    "onehot_encoded1 = onehot_encoder1.fit_transform(integer_encoded1)\n",
    "print(onehot_encoded1)\n",
    "\n",
    "a2 = data['regional_mobility']\n",
    "#print a\n",
    "a2.fillna(data['regional_mobility'].median(), inplace = True)\n",
    "# print a\n",
    "b2 = a2.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder2 = LabelEncoder()\n",
    "integer_encoded2 = label_encoder2.fit_transform(b2)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder2 = OneHotEncoder(sparse=False)\n",
    "integer_encoded2 = integer_encoded2.reshape(len(integer_encoded2), 1)\n",
    "onehot_encoded2 = onehot_encoder2.fit_transform(integer_encoded2)\n",
    "print(onehot_encoded2)\n",
    "\n",
    "a3 = data['reg_preference_for_trad']\n",
    "#print a\n",
    "a3.fillna(data['reg_preference_for_trad'].max(), inplace = True)\n",
    "# print a\n",
    "b3 = a3.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder3 = LabelEncoder()\n",
    "integer_encoded3 = label_encoder3.fit_transform(b3)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder3 = OneHotEncoder(sparse=False)\n",
    "integer_encoded3 = integer_encoded3.reshape(len(integer_encoded3), 1)\n",
    "onehot_encoded3 = onehot_encoder3.fit_transform(integer_encoded3)\n",
    "print(onehot_encoded3)\n",
    "\n",
    "a4 = data['is_high_user']\n",
    "# print a4\n",
    "a4.fillna(data['is_high_user'].max(), inplace = True)\n",
    "# print a\n",
    "b4 = a4.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder4 = LabelEncoder()\n",
    "integer_encoded4 = label_encoder4.fit_transform(b4)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder4 = OneHotEncoder(sparse=False)\n",
    "integer_encoded4 = integer_encoded4.reshape(len(integer_encoded4), 1)\n",
    "onehot_encoded4 = onehot_encoder4.fit_transform(integer_encoded4)\n",
    "print(onehot_encoded4)\n",
    "\n",
    "print onehot_encoded1.shape, onehot_encoded2.shape, onehot_encoded3.shape, onehot_encoded4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.6'></a>\n",
    "## 1.6 构造特征矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 75)\n",
      "(4754, 91)\n",
      "(4754,)\n"
     ]
    }
   ],
   "source": [
    "# 特征矩阵X\n",
    "print data_temp.shape\n",
    "import numpy as np\n",
    "X = np.hstack([data_temp, onehot_encoded1, onehot_encoded2, onehot_encoded3, onehot_encoded4, b5])\n",
    "print X.shape\n",
    "# 预测变量y\n",
    "y = data['status']\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id='1.7'></a>\n",
    "## 1.7 划分训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=1, test_size=0.3,\n",
      "            train_size=None)\n",
      "('Train Index:', array([4151,  381,  104, ..., 3500,  278,  961]), ',Test Index:', array([2593, 2388, 3542, ..., 3250,  377, 2418]))\n"
     ]
    }
   ],
   "source": [
    "# 划分训练集测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=1)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "\n",
    "for train_index,test_index in sss.split(X,y):\n",
    "    print(\"Train Index:\",train_index,\",Test Index:\",test_index)\n",
    "    X_train, X_test=X[train_index],X[test_index]\n",
    "    y_train, y_test=y[train_index],y[test_index]\n",
    "    # print(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "# 2 模型选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "## 2.1 LR模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[准确性]\n",
      "训练集： 0.802524797115\n",
      "测试集： 0.803784162579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78692431]\n",
      " [ 0.91232501]\n",
      " [ 0.85748486]\n",
      " ..., \n",
      " [ 0.90865681]\n",
      " [ 0.80359218]\n",
      " [ 0.39740008]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "continuous format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-11dc568b4ab7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtest_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#验证集上的auc值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest_auc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wangzhongpu/anaconda/lib/python2.7/site-packages/sklearn/metrics/ranking.pyc\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    258\u001b[0m     return _average_binary_score(\n\u001b[1;32m    259\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/wangzhongpu/anaconda/lib/python2.7/site-packages/sklearn/metrics/base.pyc\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multilabel-indicator\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: continuous format is not supported"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lr.predict_proba(X_train)\n",
    "y_test_pred = lr.predict_proba(X_test)\n",
    "print y_test_pred[:,[0]]\n",
    "\n",
    "# auc\n",
    "test_auc = metrics.roc_auc_score(y_test_pred[:,[0]], y_test_pred) #验证集上的auc值\n",
    "print test_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "## 2.2 SVM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[准确性]\n",
      "训练集： 0.993988578299\n",
      "测试集： 0.751927119832\n",
      "f1 score：\n",
      "训练集：0.9879\n",
      "测试集：0.0380\n",
      "ROC AUC：\n",
      "训练集：0.9880\n",
      "测试集：0.5084\n",
      "[准确性]\n",
      "训练集： 0.794409377818\n",
      "测试集： 0.798878766643\n",
      "f1 score：\n",
      "训练集：0.4384\n",
      "测试集：0.4636\n",
      "ROC AUC：\n",
      "训练集：0.6366\n",
      "测试集：0.6484\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from  sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "svc = SVC(C=1.0, kernel='rbf', gamma=0.1)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#lin_svc模型\n",
    "Lin_SVC = LinearSVC()\n",
    "Lin_SVC.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = svc.predict(X_train)\n",
    "y_test_pred = svc.predict(X_test)\n",
    "\n",
    "# print y_train[0:100]\n",
    "print y_test_pred[0:100]\n",
    "print y_test_pred[100:200]\n",
    "\n",
    "# SVM预测结果都是同一个值，可能原因有：1. 可能是由于样本数据没有归一化导致的。由于维度太大，如果不采用归一化处理的话，各个点的距离值将非常大，\n",
    "# 故模型对于待预测点的预测结果值都判为同一个值。2. 也有可能是参数的问题。\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))\n",
    "\n",
    "y_train_pred = Lin_SVC.predict(X_train)\n",
    "y_test_pred = Lin_SVC.predict(X_test)\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.3'></a>\n",
    "## 2.3 DT模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1]\n",
      "[准确性]\n",
      "训练集： 0.702735196874\n",
      "测试集： 0.668535388928\n",
      "f1 score：\n",
      "训练集：0.5547\n",
      "测试集：0.5188\n",
      "ROC AUC：\n",
      "训练集：0.7144\n",
      "测试集：0.6831\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print y_test_pred[0:100]\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.4'></a>\n",
    "## 2.4 XGBoost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0 0 0 ..., 0 0 0]\n",
      "[准确性]\n",
      "测试集： 0.78976874562\n",
      "f1 score：\n",
      "测试集：0.4774\n",
      "ROC AUC：\n",
      "测试集：0.6544\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = xgb.predict(X_test)\n",
    "\n",
    "print y_test_pred\n",
    "\n",
    "print '[准确性]'\n",
    "print '测试集：', xgb.score(X_test, y_test)\n",
    "print('f1 score：')\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.5'></a>\n",
    "## 2.5 LightGBM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgb = LGBMClassifier()\n",
    "lgb.fit(X_train, y_train)\n",
    "\n",
    "y_test_pred = lgb.predict(X_test)\n",
    "\n",
    "print y_test_pred\n",
    "\n",
    "print '[准确性]'\n",
    "print '测试集：', lgb.score(X_test, y_test)\n",
    "print('f1 score：')\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
