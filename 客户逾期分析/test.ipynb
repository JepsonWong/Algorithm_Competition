{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 90)\n"
     ]
    }
   ],
   "source": [
    "#encoding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.read_csv('data/data.csv', encoding='GB18030')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                                u'Unnamed: 0',\n",
       "                                           u'custid',\n",
       "                                         u'trade_no',\n",
       "                                     u'bank_card_no',\n",
       "                               u'low_volume_percent',\n",
       "                            u'middle_volume_percent',\n",
       "            u'take_amount_in_later_12_month_highest',\n",
       "                u'trans_amount_increase_rate_lately',\n",
       "                             u'trans_activity_month',\n",
       "                               u'trans_activity_day',\n",
       "                                       u'transd_mcc',\n",
       "                       u'trans_days_interval_filter',\n",
       "                              u'trans_days_interval',\n",
       "                                u'regional_mobility',\n",
       "                                  u'student_feature',\n",
       "                             u'repayment_capability',\n",
       "                                     u'is_high_user',\n",
       "                        u'number_of_trans_from_2011',\n",
       "                           u'first_transaction_time',\n",
       "                          u'historical_trans_amount',\n",
       "                             u'historical_trans_day',\n",
       "                                u'rank_trad_1_month',\n",
       "                             u'trans_amount_3_month',\n",
       "                  u'avg_consume_less_12_valid_month',\n",
       "                                              u'abs',\n",
       "                     u'top_trans_count_last_1_month',\n",
       "                          u'avg_price_last_12_month',\n",
       "                u'avg_price_top_last_12_valid_month',\n",
       "                          u'reg_preference_for_trad',\n",
       "                      u'trans_top_time_last_1_month',\n",
       "                      u'trans_top_time_last_6_month',\n",
       "                    u'consume_top_time_last_1_month',\n",
       "                    u'consume_top_time_last_6_month',\n",
       "                 u'cross_consume_count_last_1_month',\n",
       "           u'trans_fail_top_count_enum_last_1_month',\n",
       "           u'trans_fail_top_count_enum_last_6_month',\n",
       "          u'trans_fail_top_count_enum_last_12_month',\n",
       "                   u'consume_mini_time_last_1_month',\n",
       "             u'max_cumulative_consume_later_1_month',\n",
       "                  u'max_consume_count_later_6_month',\n",
       "              u'railway_consume_count_last_12_month',\n",
       "       u'pawns_auctions_trusts_consume_last_1_month',\n",
       "       u'pawns_auctions_trusts_consume_last_6_month',\n",
       "               u'jewelry_consume_count_last_6_month',\n",
       "                                           u'status',\n",
       "                                           u'source',\n",
       "                            u'first_transaction_day',\n",
       "                          u'trans_day_last_12_month',\n",
       "                                          u'id_name',\n",
       "                                      u'apply_score',\n",
       "                                u'apply_credibility',\n",
       "                                  u'query_org_count',\n",
       "                              u'query_finance_count',\n",
       "                                 u'query_cash_count',\n",
       "                                  u'query_sum_count',\n",
       "                                u'latest_query_time',\n",
       "                           u'latest_one_month_apply',\n",
       "                         u'latest_three_month_apply',\n",
       "                           u'latest_six_month_apply',\n",
       "                                      u'loans_score',\n",
       "                       u'loans_credibility_behavior',\n",
       "                                      u'loans_count',\n",
       "                               u'loans_settle_count',\n",
       "                              u'loans_overdue_count',\n",
       "                         u'loans_org_count_behavior',\n",
       "                       u'consfin_org_count_behavior',\n",
       "                                 u'loans_cash_count',\n",
       "                            u'latest_one_month_loan',\n",
       "                          u'latest_three_month_loan',\n",
       "                            u'latest_six_month_loan',\n",
       "                                  u'history_suc_fee',\n",
       "                                 u'history_fail_fee',\n",
       "                             u'latest_one_month_suc',\n",
       "                            u'latest_one_month_fail',\n",
       "                                  u'loans_long_time',\n",
       "                                u'loans_latest_time',\n",
       "                               u'loans_credit_limit',\n",
       "                          u'loans_credibility_limit',\n",
       "                          u'loans_org_count_current',\n",
       "                              u'loans_product_count',\n",
       "                                  u'loans_max_limit',\n",
       "                                  u'loans_avg_limit',\n",
       "                             u'consfin_credit_limit',\n",
       "                              u'consfin_credibility',\n",
       "                        u'consfin_org_count_current',\n",
       "                            u'consfin_product_count',\n",
       "                                u'consfin_max_limit',\n",
       "                                u'consfin_avg_limit',\n",
       "                                 u'latest_query_day',\n",
       "                                 u'loans_latest_day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'source'和'bank_card_no'值无区分度\n",
    "# ‘custid’、‘trade_no’、‘id_name’和预测无关\n",
    "data = data.drop(['custid', 'trade_no', 'bank_card_no', 'id_name', 'source'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 'Unnamed: 0'和预测无关\n",
    "data = data.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 先删除data\n",
    "data = data.drop(['first_transaction_time', 'latest_query_time', 'loans_latest_time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04% low_volume_percent\n",
      "0.04% middle_volume_percent\n",
      "0.00% take_amount_in_later_12_month_highest\n",
      "0.06% trans_amount_increase_rate_lately\n",
      "0.04% trans_activity_month\n",
      "0.04% trans_activity_day\n",
      "0.04% transd_mcc\n",
      "0.17% trans_days_interval_filter\n",
      "0.04% trans_days_interval\n",
      "0.04% regional_mobility\n",
      "63.06% student_feature\n",
      "0.00% repayment_capability\n",
      "0.00% is_high_user\n",
      "0.04% number_of_trans_from_2011\n",
      "0.00% historical_trans_amount\n",
      "0.04% historical_trans_day\n",
      "0.04% rank_trad_1_month\n",
      "0.00% trans_amount_3_month\n",
      "0.04% avg_consume_less_12_valid_month\n",
      "0.00% abs\n",
      "0.04% top_trans_count_last_1_month\n",
      "0.00% avg_price_last_12_month\n",
      "2.19% avg_price_top_last_12_valid_month\n",
      "0.04% reg_preference_for_trad\n",
      "0.17% trans_top_time_last_1_month\n",
      "0.17% trans_top_time_last_6_month\n",
      "0.17% consume_top_time_last_1_month\n",
      "0.17% consume_top_time_last_6_month\n",
      "8.96% cross_consume_count_last_1_month\n",
      "0.34% trans_fail_top_count_enum_last_1_month\n",
      "0.34% trans_fail_top_count_enum_last_6_month\n",
      "0.34% trans_fail_top_count_enum_last_12_month\n",
      "0.55% consume_mini_time_last_1_month\n",
      "0.00% max_cumulative_consume_later_1_month\n",
      "0.17% max_consume_count_later_6_month\n",
      "0.25% railway_consume_count_last_12_month\n",
      "0.00% pawns_auctions_trusts_consume_last_1_month\n",
      "0.00% pawns_auctions_trusts_consume_last_6_month\n",
      "0.25% jewelry_consume_count_last_6_month\n",
      "0.00% status\n",
      "0.04% first_transaction_day\n",
      "0.04% trans_day_last_12_month\n",
      "6.39% apply_score\n",
      "6.39% apply_credibility\n",
      "6.39% query_org_count\n",
      "6.39% query_finance_count\n",
      "6.39% query_cash_count\n",
      "6.39% query_sum_count\n",
      "6.39% latest_one_month_apply\n",
      "6.39% latest_three_month_apply\n",
      "6.39% latest_six_month_apply\n",
      "6.25% loans_score\n",
      "6.25% loans_credibility_behavior\n",
      "6.25% loans_count\n",
      "6.25% loans_settle_count\n",
      "6.25% loans_overdue_count\n",
      "6.25% loans_org_count_behavior\n",
      "6.25% consfin_org_count_behavior\n",
      "6.25% loans_cash_count\n",
      "6.25% latest_one_month_loan\n",
      "6.25% latest_three_month_loan\n",
      "6.25% latest_six_month_loan\n",
      "6.25% history_suc_fee\n",
      "6.25% history_fail_fee\n",
      "6.25% latest_one_month_suc\n",
      "6.25% latest_one_month_fail\n",
      "6.25% loans_long_time\n",
      "6.25% loans_credit_limit\n",
      "6.25% loans_credibility_limit\n",
      "6.25% loans_org_count_current\n",
      "6.25% loans_product_count\n",
      "6.25% loans_max_limit\n",
      "6.25% loans_avg_limit\n",
      "6.25% consfin_credit_limit\n",
      "6.25% consfin_credibility\n",
      "6.25% consfin_org_count_current\n",
      "6.25% consfin_product_count\n",
      "6.25% consfin_max_limit\n",
      "6.25% consfin_avg_limit\n",
      "6.39% latest_query_day\n",
      "6.25% loans_latest_day\n"
     ]
    }
   ],
   "source": [
    "# 统计各个列缺失值所占比例\n",
    "for i in data.columns:\n",
    "    d = len(data) - data[i].count()\n",
    "    r = (float(d) / len(data)) * 100\n",
    "    # rate = '%.2f%%' % r\n",
    "    # print 'name: ', str(i).ljust(10),'d: ', str(d).ljust(4), 'rate: ', rate\n",
    "    print '%.2f%%' % r, i\n",
    "\n",
    "# 由下图统计可以看出，‘student_feature’列缺失一半以上，且本列为类别类型，可以将缺失值用-1填充，相当于“是否缺失”当成另一种类别。\n",
    "# 其他列缺失概率比较小，可以用中值填充。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 81)\n",
      "(4754, 82)\n"
     ]
    }
   ],
   "source": [
    "# 缺失个数作为一种特征，衡量用户的信息完善程度\n",
    "miss_rate = []\n",
    "for i in range(len(data)):\n",
    "    temp = float((data[i:i+1]).count().sum()) / len(data.columns)\n",
    "    miss_rate.append(temp)\n",
    "\n",
    "print data.shape\n",
    "data['miss_rate'] = miss_rate\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.987654\n",
      "1       1.000000\n",
      "2       0.987654\n",
      "3       0.987654\n",
      "4       0.987654\n",
      "5       1.000000\n",
      "6       0.962963\n",
      "7       0.506173\n",
      "8       0.987654\n",
      "9       1.000000\n",
      "10      0.987654\n",
      "11      1.000000\n",
      "12      1.000000\n",
      "13      0.975309\n",
      "14      0.987654\n",
      "15      0.987654\n",
      "16      0.987654\n",
      "17      1.000000\n",
      "18      1.000000\n",
      "19      0.987654\n",
      "20      1.000000\n",
      "21      0.987654\n",
      "22      0.987654\n",
      "23      0.987654\n",
      "24      1.000000\n",
      "25      0.975309\n",
      "26      1.000000\n",
      "27      1.000000\n",
      "28      1.000000\n",
      "29      0.876543\n",
      "          ...   \n",
      "4724    1.000000\n",
      "4725    0.975309\n",
      "4726    0.987654\n",
      "4727    0.987654\n",
      "4728    0.987654\n",
      "4729    0.975309\n",
      "4730    1.000000\n",
      "4731    1.000000\n",
      "4732    0.975309\n",
      "4733    0.987654\n",
      "4734    0.987654\n",
      "4735    1.000000\n",
      "4736    1.000000\n",
      "4737    1.000000\n",
      "4738    0.987654\n",
      "4739    0.987654\n",
      "4740    0.987654\n",
      "4741    1.000000\n",
      "4742    1.000000\n",
      "4743    0.987654\n",
      "4744    0.987654\n",
      "4745    0.987654\n",
      "4746    0.518519\n",
      "4747    0.987654\n",
      "4748    0.975309\n",
      "4749    1.000000\n",
      "4750    1.000000\n",
      "4751    0.987654\n",
      "4752    0.987654\n",
      "4753    1.000000\n",
      "Name: miss_rate, Length: 4754, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print data['miss_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    1950\n",
       "2.0    1515\n",
       "4.0     802\n",
       "1.0     446\n",
       "5.0      39\n",
       "Name: regional_mobility, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'regional_mobility'列的统计，按类别特征处理\n",
    "data['regional_mobility'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "一线城市    3403\n",
       "三线城市    1064\n",
       "境外       150\n",
       "二线城市     131\n",
       "其他城市       4\n",
       "Name: reg_preference_for_trad, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'reg_preference_for_trad'列的统计，按类别特征处理\n",
    "data['reg_preference_for_trad'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1754\n",
       "2.0       2\n",
       "Name: student_feature, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'student_feature'列的统计，按类别特征处理\n",
    "data['student_feature'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4701\n",
       "1      53\n",
       "Name: is_high_user, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'is_high_user'列的统计，按类别特征处理\n",
    "data['is_high_user'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3561\n",
       "1    1193\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'status'列的统计，预测变量，正负样本接近1：3，可以不做处理。\n",
    "data['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 76)\n",
      "(4754, 82)\n"
     ]
    }
   ],
   "source": [
    "# 将刚刚被归类为类别变量和预测变量的列去掉，生成data_temp，数值特征为77维，类别特征为5维\n",
    "data_temp = data\n",
    "data_temp = data_temp.drop(['regional_mobility', 'reg_preference_for_trad', 'student_feature', 'is_high_user', 'status', 'miss_rate'], axis = 1)\n",
    "print data_temp.shape\n",
    "print data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "0.04 low_volume_percent\n",
      "0.14 middle_volume_percent\n",
      "3923.97 take_amount_in_later_12_month_highest\n",
      "694.18 trans_amount_increase_rate_lately\n",
      "0.20 trans_activity_month\n",
      "0.17 trans_activity_day\n",
      "4.48 transd_mcc\n",
      "22.72 trans_days_interval_filter\n",
      "16.47 trans_days_interval\n",
      "52217.83 repayment_capability\n",
      "10.06 number_of_trans_from_2011\n",
      "320493.12 historical_trans_amount\n",
      "99.69 historical_trans_day\n",
      "0.26 rank_trad_1_month\n",
      "101746.13 trans_amount_3_month\n",
      "1.39 avg_consume_less_12_valid_month\n",
      "27007.60 abs\n",
      "0.35 top_trans_count_last_1_month\n",
      "765.87 avg_price_last_12_month\n",
      "0.10 avg_price_top_last_12_valid_month\n",
      "5.32 trans_top_time_last_1_month\n",
      "12.96 trans_top_time_last_6_month\n",
      "5.46 consume_top_time_last_1_month\n",
      "13.13 consume_top_time_last_6_month\n",
      "2.34 cross_consume_count_last_1_month\n",
      "1.91 trans_fail_top_count_enum_last_1_month\n",
      "4.46 trans_fail_top_count_enum_last_6_month\n",
      "4.76 trans_fail_top_count_enum_last_12_month\n",
      "374267.23 consume_mini_time_last_1_month\n",
      "10813.45 max_cumulative_consume_later_1_month\n",
      "5.68 max_consume_count_later_6_month\n",
      "0.48 railway_consume_count_last_12_month\n",
      "6616.69 pawns_auctions_trusts_consume_last_1_month\n",
      "28191.13 pawns_auctions_trusts_consume_last_6_month\n",
      "0.20 jewelry_consume_count_last_6_month\n",
      "537.11 first_transaction_day\n",
      "19.07 trans_day_last_12_month\n",
      "51.17 apply_score\n",
      "4.17 apply_credibility\n",
      "7.04 query_org_count\n",
      "3.81 query_finance_count\n",
      "2.60 query_cash_count\n",
      "11.30 query_sum_count\n",
      "4.53 latest_one_month_apply\n",
      "7.62 latest_three_month_apply\n",
      "9.27 latest_six_month_apply\n",
      "60.95 loans_score\n",
      "2.23 loans_credibility_behavior\n",
      "24.61 loans_count\n",
      "21.69 loans_settle_count\n",
      "3.15 loans_overdue_count\n",
      "7.45 loans_org_count_behavior\n",
      "2.97 consfin_org_count_behavior\n",
      "5.37 loans_cash_count\n",
      "1.50 latest_one_month_loan\n",
      "3.46 latest_three_month_loan\n",
      "10.83 latest_six_month_loan\n",
      "30.35 history_suc_fee\n",
      "25.09 history_fail_fee\n",
      "1.94 latest_one_month_suc\n",
      "3.89 latest_one_month_fail\n",
      "35.77 loans_long_time\n",
      "708.95 loans_credit_limit\n",
      "10.85 loans_credibility_limit\n",
      "5.37 loans_org_count_current\n",
      "5.76 loans_product_count\n",
      "1474.21 loans_max_limit\n",
      "583.42 loans_avg_limit\n",
      "7371.26 consfin_credit_limit\n",
      "14.54 consfin_credibility\n",
      "2.97 consfin_org_count_current\n",
      "3.41 consfin_product_count\n",
      "14301.04 consfin_max_limit\n",
      "5679.42 consfin_avg_limit\n",
      "37.73 latest_query_day\n",
      "53.49 loans_latest_day\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "# 统计各个列标准差，将标准差小于0.1的特征剔除，数值特征变为71维\n",
    "print (len(data_temp.columns))\n",
    "for i in data_temp.columns:\n",
    "    r = data_temp[i].std()\n",
    "    print '%.2f' % r, i\n",
    "    \n",
    "    if r < 0.1:\n",
    "        data_temp = data_temp.drop([i], axis = 1)\n",
    "print (len(data_temp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "middle_volume_percent\n",
      "trans_amount_increase_rate_lately\n",
      "trans_activity_month\n",
      "trans_activity_day\n",
      "transd_mcc\n",
      "trans_days_interval_filter\n",
      "trans_days_interval\n",
      "number_of_trans_from_2011\n",
      "historical_trans_day\n",
      "rank_trad_1_month\n",
      "avg_consume_less_12_valid_month\n",
      "top_trans_count_last_1_month\n",
      "avg_price_top_last_12_valid_month\n",
      "trans_top_time_last_1_month\n",
      "trans_top_time_last_6_month\n",
      "consume_top_time_last_1_month\n",
      "consume_top_time_last_6_month\n",
      "cross_consume_count_last_1_month\n",
      "trans_fail_top_count_enum_last_1_month\n",
      "trans_fail_top_count_enum_last_6_month\n",
      "trans_fail_top_count_enum_last_12_month\n",
      "consume_mini_time_last_1_month\n",
      "max_consume_count_later_6_month\n",
      "railway_consume_count_last_12_month\n",
      "jewelry_consume_count_last_6_month\n",
      "first_transaction_day\n",
      "trans_day_last_12_month\n",
      "apply_score\n",
      "apply_credibility\n",
      "query_org_count\n",
      "query_finance_count\n",
      "query_cash_count\n",
      "query_sum_count\n",
      "latest_one_month_apply\n",
      "latest_three_month_apply\n",
      "latest_six_month_apply\n",
      "loans_score\n",
      "loans_credibility_behavior\n",
      "loans_count\n",
      "loans_settle_count\n",
      "loans_overdue_count\n",
      "loans_org_count_behavior\n",
      "consfin_org_count_behavior\n",
      "loans_cash_count\n",
      "latest_one_month_loan\n",
      "latest_three_month_loan\n",
      "latest_six_month_loan\n",
      "history_suc_fee\n",
      "history_fail_fee\n",
      "latest_one_month_suc\n",
      "latest_one_month_fail\n",
      "loans_long_time\n",
      "loans_credit_limit\n",
      "loans_credibility_limit\n",
      "loans_org_count_current\n",
      "loans_product_count\n",
      "loans_max_limit\n",
      "loans_avg_limit\n",
      "consfin_credit_limit\n",
      "consfin_credibility\n",
      "consfin_org_count_current\n",
      "consfin_product_count\n",
      "consfin_max_limit\n",
      "consfin_avg_limit\n",
      "latest_query_day\n",
      "loans_latest_day\n"
     ]
    }
   ],
   "source": [
    "# 接下来对类别特征和数值特征进行填充\n",
    "# 数值特征和类别特征均用用中值进行填充\n",
    "# 缺失值特征特别大的特征‘student_feature’用‘-1’填充\n",
    "for i in data_temp.columns:\n",
    "    temp = data_temp[i].isnull().sum()\n",
    "    if temp:\n",
    "        print i\n",
    "        data_temp[i].fillna(data_temp[i].median(), inplace = True)\n",
    "\n",
    "# 数值特征归一化 \n",
    "# 从sklearn.preprocessing导入StandardScaler  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "# 标准化数据，保证每个维度的特征数据方差为1，均值为0，使得预测结果不会被某些维度过大的特征值而主导  \n",
    "ss = StandardScaler()  \n",
    "# fit_transform()先拟合数据，再标准化  \n",
    "data_temp = ss.fit_transform(data_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98765432  1.          0.98765432 ...,  0.98765432  0.98765432  1.        ]\n",
      "(4754,)\n",
      "(4754, 1)\n"
     ]
    }
   ],
   "source": [
    "a5 = data['miss_rate']\n",
    "b5 = a5.as_matrix()\n",
    "print b5\n",
    "print b5.shape\n",
    "b5 = b5.reshape(len(b5), 1)\n",
    "print b5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.]\n",
      " [ 1.  0.  0.]\n",
      " [ 0.  1.  0.]]\n",
      "[[ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  1.  0.  0.  0.]]\n",
      "[[ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.]]\n",
      "[[ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " ..., \n",
      " [ 1.  0.]\n",
      " [ 1.  0.]\n",
      " [ 1.  0.]]\n",
      "(4754, 3) (4754, 5) (4754, 5) (4754, 2)\n"
     ]
    }
   ],
   "source": [
    "# 类别特征one-hot编码\n",
    "\n",
    "a1 = data['student_feature']\n",
    "#print a\n",
    "a1.fillna(-1, inplace = True)\n",
    "# print a\n",
    "b1 = a1.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder1 = LabelEncoder()\n",
    "integer_encoded1 = label_encoder1.fit_transform(b1)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder1 = OneHotEncoder(sparse=False)\n",
    "integer_encoded1 = integer_encoded1.reshape(len(integer_encoded1), 1)\n",
    "onehot_encoded1 = onehot_encoder1.fit_transform(integer_encoded1)\n",
    "print(onehot_encoded1)\n",
    "\n",
    "a2 = data['regional_mobility']\n",
    "#print a\n",
    "a2.fillna(data['regional_mobility'].median(), inplace = True)\n",
    "# print a\n",
    "b2 = a2.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder2 = LabelEncoder()\n",
    "integer_encoded2 = label_encoder2.fit_transform(b2)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder2 = OneHotEncoder(sparse=False)\n",
    "integer_encoded2 = integer_encoded2.reshape(len(integer_encoded2), 1)\n",
    "onehot_encoded2 = onehot_encoder2.fit_transform(integer_encoded2)\n",
    "print(onehot_encoded2)\n",
    "\n",
    "a3 = data['reg_preference_for_trad']\n",
    "#print a\n",
    "a3.fillna(data['reg_preference_for_trad'].max(), inplace = True)\n",
    "# print a\n",
    "b3 = a3.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder3 = LabelEncoder()\n",
    "integer_encoded3 = label_encoder3.fit_transform(b3)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder3 = OneHotEncoder(sparse=False)\n",
    "integer_encoded3 = integer_encoded3.reshape(len(integer_encoded3), 1)\n",
    "onehot_encoded3 = onehot_encoder3.fit_transform(integer_encoded3)\n",
    "print(onehot_encoded3)\n",
    "\n",
    "a4 = data['is_high_user']\n",
    "# print a4\n",
    "a4.fillna(data['is_high_user'].max(), inplace = True)\n",
    "# print a\n",
    "b4 = a4.as_matrix()\n",
    "# print b.shape (4754,)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "label_encoder4 = LabelEncoder()\n",
    "integer_encoded4 = label_encoder4.fit_transform(b4)\n",
    "# print(integer_encoded)\n",
    "# binary encode\n",
    "onehot_encoder4 = OneHotEncoder(sparse=False)\n",
    "integer_encoded4 = integer_encoded4.reshape(len(integer_encoded4), 1)\n",
    "onehot_encoded4 = onehot_encoder4.fit_transform(integer_encoded4)\n",
    "print(onehot_encoded4)\n",
    "\n",
    "print onehot_encoded1.shape, onehot_encoded2.shape, onehot_encoded3.shape, onehot_encoded4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4754, 75)\n",
      "(4754, 91)\n",
      "(4754,)\n"
     ]
    }
   ],
   "source": [
    "# 特征矩阵X\n",
    "print data_temp.shape\n",
    "import numpy as np\n",
    "X = np.hstack([data_temp, onehot_encoded1, onehot_encoded2, onehot_encoded3, onehot_encoded4, b5])\n",
    "print X.shape\n",
    "# 预测变量y\n",
    "y = data['status']\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=1, random_state=1, test_size=0.3,\n",
      "            train_size=None)\n",
      "('Train Index:', array([4151,  381,  104, ..., 3500,  278,  961]), ',Test Index:', array([2593, 2388, 3542, ..., 3250,  377, 2418]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练集测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=23)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=1,test_size=0.3,random_state=1)\n",
    "sss.get_n_splits(X, y)\n",
    "print(sss)\n",
    "\n",
    "for train_index,test_index in sss.split(X,y):\n",
    "    print(\"Train Index:\",train_index,\",Test Index:\",test_index)\n",
    "    X_train, X_test=X[train_index],X[test_index]\n",
    "    y_train, y_test=y[train_index],y[test_index]\n",
    "    # print(X_train,X_test,y_train,y_test)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[准确性]\n",
      "训练集： 0.802524797115\n",
      "测试集： 0.803784162579\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 准确性\n",
    "y_train_pred = lr.predict_proba(X_train)\n",
    "y_test_pred = lr.predict_proba(X_test)\n",
    "print y_test_pred[:,[0]]\n",
    "\n",
    "# auc\n",
    "test_auc = metrics.roc_auc_score(y_test_pred[:,[0]], y_test_pred) #验证集上的auc值\n",
    "print test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4151    1\n",
      "381     0\n",
      "104     0\n",
      "3722    0\n",
      "1963    0\n",
      "3729    0\n",
      "3058    0\n",
      "1741    0\n",
      "3106    0\n",
      "2276    0\n",
      "3949    0\n",
      "2636    0\n",
      "2947    0\n",
      "1456    0\n",
      "4460    0\n",
      "4735    1\n",
      "4513    1\n",
      "1135    1\n",
      "877     0\n",
      "3321    0\n",
      "3094    0\n",
      "1793    0\n",
      "1830    0\n",
      "4753    0\n",
      "1816    0\n",
      "2075    1\n",
      "2411    0\n",
      "2367    1\n",
      "537     0\n",
      "1535    0\n",
      "       ..\n",
      "1719    0\n",
      "1208    0\n",
      "3       0\n",
      "4677    0\n",
      "319     1\n",
      "2773    0\n",
      "3340    1\n",
      "2008    0\n",
      "390     0\n",
      "2014    0\n",
      "141     0\n",
      "3946    0\n",
      "1619    0\n",
      "3444    1\n",
      "2710    0\n",
      "4316    0\n",
      "3290    0\n",
      "3852    0\n",
      "3793    1\n",
      "2838    0\n",
      "3338    1\n",
      "1420    1\n",
      "1744    0\n",
      "2343    1\n",
      "509     0\n",
      "2523    1\n",
      "1243    0\n",
      "631     0\n",
      "2833    0\n",
      "3923    1\n",
      "Name: status, Length: 100, dtype: int64\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[准确性]\n",
      "训练集： 0.993988578299\n",
      "测试集： 0.751927119832\n",
      "f1 score：\n",
      "训练集：0.9879\n",
      "测试集：0.0380\n",
      "ROC AUC：\n",
      "训练集：0.9880\n",
      "测试集：0.5084\n",
      "[准确性]\n",
      "训练集： 0.795611662158\n",
      "测试集： 0.798878766643\n",
      "f1 score：\n",
      "训练集：0.4408\n",
      "测试集：0.4615\n",
      "ROC AUC：\n",
      "训练集：0.6378\n",
      "测试集：0.6475\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from  sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "svc = SVC(C=1.0, kernel='rbf', gamma=0.1)\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "#lin_svc模型\n",
    "Lin_SVC = LinearSVC()\n",
    "Lin_SVC.fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = svc.predict(X_train)\n",
    "y_test_pred = svc.predict(X_test)\n",
    "\n",
    "print y_train[0:100]\n",
    "print y_test_pred[0:100]\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))\n",
    "\n",
    "y_train_pred = Lin_SVC.predict(X_train)\n",
    "y_test_pred = Lin_SVC.predict(X_test)\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 1 0 1 0 1 0 1 0 0 0\n",
      " 0 0 0 1 1 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1\n",
      " 1 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 0 0 0 0 0 0 1 1 1 1]\n",
      "[准确性]\n",
      "训练集： 0.702735196874\n",
      "测试集： 0.668535388928\n",
      "f1 score：\n",
      "训练集：0.5547\n",
      "测试集：0.5188\n",
      "ROC AUC：\n",
      "训练集：0.7144\n",
      "测试集：0.6831\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(class_weight='balanced', criterion='gini', max_depth=4,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=None, splitter='best')\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "\n",
    "print y_test_pred[0:100]\n",
    "\n",
    "print '[准确性]'\n",
    "print '训练集：', accuracy_score(y_train, y_train_pred)\n",
    "print '测试集：', accuracy_score(y_test, y_test_pred)\n",
    "print('f1 score：')\n",
    "print('训练集：{:.4f}'.format(f1_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(f1_score(y_test, y_test_pred)))\n",
    "print('ROC AUC：')\n",
    "print('训练集：{:.4f}'.format(roc_auc_score(y_train, y_train_pred)))\n",
    "print('测试集：{:.4f}'.format(roc_auc_score(y_test, y_test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
